{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "name": "",
  "signature": "sha256:4a4b2c736dbeecb3ec1119432a29fc184866e8e8c9afca3f3ae287a1dbb293b4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Asynchronous Programming with OpenACC"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This lab is intended for C/C++ programmers. If you prefer to use Fortran, click [this link.](../Fortran/Lab7_Fortran.ipynb)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "## Introduction\n",
      "\n",
      "Asynchronous programming is a programming technique such that two or more unrelated operations can occur independently or even at the same time without immediate synchronization. In OpenACC, when we refer to asynchronous programming we are generally referring to performing accelerated computation while simultaneously performing data transfers between host and device, enqueuing additional work to keep the device busy, performing unrelated work on the host CPU, or even sending work to two different devices simultaneously (more on this in a future lab!). The goal for this lab is to use the OpenACC **async** clause to speedup a code by *overlapping* our compute with our data movement."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "## Analyze the Code\n",
      "\n",
      "The code we will be using for this lab is an image filtering code. Click the following links to view the code before we begin analyzing it.\n",
      "\n",
      "[main.cpp](/edit/C/main.cpp)  \n",
      "[filter.c](/edit/C/NoBlocking/filter.c)  \n",
      "\n",
      "All of our changes will be done in *filter.c*. We will start off with a very simple parallelization of the *blur5* function, and by the end of the lab have a more optimized version using OpenACC **async**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "## OpenACC Async Clause\n",
      "\n",
      "We use the **async** clause to specify code that should be run *asynchronously*. The async clause can be added to our *parallel* or *kernels* regions, and to our *enter data*, *exit data*, and *update* directives. The easiest way to explain how the async clause works is to first explain what happens when we don't use it.\n",
      "\n",
      "When no async clause is used, the host thread will pause at the end of the OpenACC region (which could be any of the directives we mentioned above). The host thread will stay paused until that region is finished. For example, if we have a loop inside of a parallel region, then that loop will be executed on the device. The host thread will wait until the kernels region is done, which means that it will wait until that loop is done running on the device. Here is a simple example:\n",
      "\n",
      "\n",
      "```c++\n",
      "int sum = 0;\n",
      "#pragma acc parallel loop reduction(+:sum)\n",
      "for(int i = 0; i < 100; i++) {\n",
      "    sum += i;\n",
      "} // Host waits here for region to complete\n",
      "\n",
      "// Host continues to the rest of the code\n",
      "\n",
      "printf(\"Summation determined as %i\\n\", sum);\n",
      "```\n",
      "\n",
      "We are expecting the host thread to wait for the parallel loop to finish before it tries to print the value of *sum*. Next, consider if we add the async clause to our parallel loop:\n",
      "\n",
      "```c++\n",
      "int sum = 0;\n",
      "#pragma acc parallel loop reduction(+:sum) async\n",
      "for(int i = 0; i < 100; i++) {\n",
      "    sum += i;\n",
      "} // Host waits here for the region to complete\n",
      "\n",
      "// Host continues to the rest of the code\n",
      "\n",
      "printf(\"Summation determined as %i\\n\", sum);\n",
      "```\n",
      "\n",
      "The host thread will **not wait** for the parallel loop to finish. This means that instead of printing the correct sum value, it will most likely print 0. This example is to show that the async clause should not always be used, as it is often important that we wait for our parallel loops, and for our data movement to finish before continuing host code. However, in some codes (like the one we will work on shortly) we can exploit the OpenACC asynchronous behavior to improve performance.\n",
      "\n",
      "### Benefits of Using Async\n",
      "\n",
      "Here are the primary benefits we can expect when using async in our code:\n",
      "\n",
      "* We can execute host and device code simultaneously. We can launch our device code with *async*, and while that executes we can go back to the host to continue unrelated (non-device dependent) code.  \n",
      "* We can *queue up* multiple device kernel launches so that they execute back-to-back, which in some cases can reduce overhead associated with launching device kernels.\n",
      "* **We can perform device computation at the same time as data movement between host and device.** This is the optimization we will be applying to our code in this lab, and is the most general use case of async\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "## Async Example\n",
      "\n",
      "Let's look at the following code example:\n",
      "\n",
      "```c++\n",
      "float *A = (float*) malloc(N * sizeof(float));\n",
      "float *B = (float*) malloc(M * sizeof(float));\n",
      "#pragma acc enter data create(A[0:N], B[0:M])\n",
      "\n",
      "// Compute Loop 1\n",
      "#pragma acc parallel loop present(A)\n",
      "for(int i = 0; i < N; i++) {\n",
      "    A[i] = ...;\n",
      "}\n",
      "\n",
      "// Update 1\n",
      "#pragma acc update self(A[0:N])\n",
      "\n",
      "// Compute Loop 2\n",
      "#pragma acc parallel loop present(B)\n",
      "for(int i = 0; i < M; i++) {\n",
      "    B[i] = ...;\n",
      "}\n",
      "\n",
      "// Update 2\n",
      "#pragma acc update self(B[0:M])\n",
      "```\n",
      "\n",
      "This code has two main restrictions: *Compute Loop 1* must finish before *Update 1* starts, and *Compute Loop 2* must finish before *Update 2* starts. This means that there is no reason to wait between *Update 1* and *Compute Loop 2*. We can use the **async clause** on *Update 1*. This will allow the code to continue onto *Compute Loop 2* without needing to wait for *Update 1* to finish.\n",
      "\n",
      "```c++\n",
      "// Update 1\n",
      "#pragma acc update self(A[0:N]) async\n",
      "```\n",
      "\n",
      "Another way we can accomplish this is by placing *Compute Loop 1*/*Update 1* and *Compute Loop 2*/*Update 2* into separate **queues**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "## OpenACC Queues\n",
      "\n",
      "Under-the-hood whenever we use the async clause, we are adding some *work* to a **queue**. Work that is in different queues can execute *asynchronously*, and work that is in the same queue will execute *sequentially* (one after the other). When we use async, we are able to specify a queue number. If no queue number is specified, then a default will automatically be used. Additionally, if there is no async clause present, the work will still be placed in a (different) default queue, known as the synchronous queue. There is an overhead associated with launching new queues, so the goal is to use the minimum number that you need, and reuse queues when possible. Let's first look at an example without using async.\n",
      "\n",
      "![Queue1](../Images/Queue1.png)\n",
      "\n",
      "Next, let's add some async and see how the work will be distributed into queues.\n",
      "\n",
      "![Queue2](../Images/Queue2.png)\n",
      "\n",
      "Since Loop1/Update1 and Loop2/Update2 are in separate queues, they will execute independently of each other. The queues are still limited by the capabilities of the device, but generally this means that if one queue is doing computation, and the other is doing data movement they can occur at the same time.\n",
      "\n",
      "We have one more problem that we have to address before working on the code."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "## OpenACC Wait\n",
      "\n",
      "Let's consider the following code:\n",
      "\n",
      "```c++\n",
      "#pragma acc parallel loop async(1)\n",
      "for(int i = 0; i < 100; i++) {\n",
      "    A[i] = 1.0;\n",
      "}\n",
      "\n",
      "#pragma acc update self(A[0:100]) async(1)\n",
      "\n",
      "#pragma acc parallel loop async(2)\n",
      "for(int i = 0; i < 100; i++) {\n",
      "    B[i] = 2.0;\n",
      "}\n",
      "\n",
      "#pragma acc update self(B[0:100]) async(2)\n",
      "\n",
      "// Back to Host Code\n",
      "for(int i = 0; i < 100; i++) {\n",
      "    printf(\"(%.1f, %.1f) \", A[i], B[i]);\n",
      "}\n",
      "```\n",
      "We want to perform the loops and data movement asynchronously for the performance benefit, but we need to make sure we pause and wait for everything to finish up before executing that printing loop on the host. We can accomplish this by using the **OpenACC wait directive**. The syntax is as follows:\n",
      "\n",
      "**\\#pragma acc wait(*queue*)**\n",
      "\n",
      "This will pause the host until the specified queue is finished. If no queue is specified, then it will wait for all queues to finish. Adding it to the above code would look like this:\n",
      "\n",
      "```c++\n",
      "#pragma acc parallel loop async(1)\n",
      "for(int i = 0; i < 100; i++) {\n",
      "    A[i] = 1.0;\n",
      "}\n",
      "\n",
      "#pragma acc update self(A[0:100]) async(1)\n",
      "\n",
      "#pragma acc parallel loop async(2)\n",
      "for(int i = 0; i < 100; i++) {\n",
      "    B[i] = 2.0;\n",
      "}\n",
      "\n",
      "#pragma acc update self(B[0:100]) async(2)\n",
      "\n",
      "#pragma acc wait\n",
      "\n",
      "// Back to Host Code\n",
      "for(int i = 0; i < 100; i++) {\n",
      "    printf(\"(%.1f, %.1f) \", A[i], B[i]);\n",
      "}\n",
      "```\n",
      "\n",
      "Let's look at our visual example from earlier with the added **wait** directive:\n",
      "\n",
      "![Queue2](../Images/Queue3.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "## Optimizing Our Code\n",
      "\n",
      "In our code, we apply a simple filter to each pixel of an image. Each pixel of the image can be computed independently from each other. Our goal is to break up the computation of the image into *blocks*, and compute each block independently. Blocking the image in this manner allows us to alternate between computing a block and transferring the data of a block. Then, we can optimize it with async.\n",
      "\n",
      "If you followed the lecture slides associated with this lab, then you should be familiar with a code called *mandelbrot*. This code implements a similar concept that we are trying to achieve; here is a visualization:\n",
      "\n",
      "![Image1](../Images/Image1.png)\n",
      "\n",
      "Here we have an image that we are breaking up (along the Y direction) into several blocks. Then we want to use async to overlap the computation of the blocks, and the data transfer back to the host. Here is a diagram of what we hope to achieve.\n",
      "\n",
      "![Image2](../Images/Image2.png)\n",
      "\n",
      "Let's run the code and get the baseline performance. Also, if you would like to view the \"before image\", you may so so [here.](/view/C/costarica.jpg)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!make clean && make"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "### Applying Blocking\n",
      "\n",
      "The first step that we will do is to apply **blocking** to the code. By blocking the code, we allow us to alternate between compute and data transfer, and will eventually let us apply the async clause.\n",
      "\n",
      "Edit the code file with [this link.](/edit/C/filter.c), and try to apply blocking to the **blur5** function. There is also blur5_serial and blur5_parallel which we will use to measure performance, so do not edit those.\n",
      "\n",
      "Blocking the code is not always easy. If you are feeling stuck, here are some hints:\n",
      "\n",
      "* First decide how many blocks you want to break it up into. You can choose a hard-coded number, or try to pick a number based off the size of the image.\n",
      "* Create a new outer block loop. This loop should go from 0 -> number_blocks\n",
      "* In the block loop, compute a lower and upper bound for your **y** loop. For example, if my image was height 100, and I have 4 blocks. For block0 I would have lower=0, upper=25. For block1 I would have lower=25, upper=50. For block2 I would have lower=50, upper=75. And lastly for block 3 I would have lower=75, upper=100.\n",
      "* Change the **y** loop to run from lower_bound -> upper_bound, instead of 0 -> image_height.\n",
      "* Move the update directives into the block loop, and change them to only update the data that you need for that block. Pay special attention to the imgData array and how it is used, you need to read offsetted values based on the size of the filter.\n",
      "\n",
      "Here is some pseudo-code to give you an idea of what to try:\n",
      "\n",
      "```\n",
      "for block from 0 -> numBlocks {\n",
      "\n",
      "    lower = block * rowsPerBlock\n",
      "    upper = lower + rowsPerBlock\n",
      "    \n",
      "    #pragma acc update device( inData[lowerDataBound*WIDTH:(upperDataBound-lowerDataBound)*WIDTH] )\n",
      "    \n",
      "    #pragma acc parallel loop\n",
      "    for y from lower -> upper {\n",
      "        for x from 0 -> WIDTH {\n",
      "            < Compute Pixel >\n",
      "        }\n",
      "    }\n",
      "            \n",
      "    #pragma acc update self( outData[lower*WIDTH:(upper-lower)*WIDTH] )\n",
      "    \n",
      "}\n",
      "```\n",
      "\n",
      "When you want to give it a try, run the following block. The code will run a result comparison test. If this test fails, it is likely that there is a mistake in the lower/upper bounds for the data movement."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!make clean && make"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There isn't a single clear-cut solution on how to apply the blocking, but if you want to view our solution to compare, you can do so [here.](/edit/C/Solution/filter_no_pipeline.c) We have all of the steps that we took that lead to our final blocked solution. Also, if you would like to see the image that the code creates, you can view it [here.](view/C/out.jpg)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "### Applying Async\n",
      "Now try adding async to the code and see if you can achieve a performance increase. Some hints to get you started:  \n",
      "\n",
      "* You must first compute a block of the image before starting the data transfer. Thus, each block compute/transfer should share a queue, and different blocks should be in different queues. (you do use something like async(block%2) to achieve alternating blocks)\n",
      "* You need to ensure that you wait for all the blocks to finish before continuing onto the rest of the host code, so you will need the wait directive.\n",
      "\n",
      "Edit the code file with [this link.](/edit/C/filter.c)  \n",
      "Re-run the code when you want to test your changes, and if you are stuck we will have the solution below! And after running, if you would like to see the output image again, use [this link.](/view/C/out.jpg)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!make clean && make"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Solutions\n",
      "\n",
      "If you would like to check our solution to this lab, click the [following link.](/edit/C/Solution/filter.c) This file contains the base version of blur5, alongside all of the steps taken to block the code, and the final async solution."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "## Bonus Task\n",
      "\n",
      "We hinted earlier to another use of OpenACC async - reducing the launch overhead of our device kernels. There is an OpenACC video tutorial series done by Michael Wolfe from PGI, and the 6th part of tutorial covers this use of OpenACC async. [Here is the link to that video.](https://youtu.be/voOcd1bNHIA)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "## Post-Lab Summary\n",
      "\n",
      "If you would like to download this lab for later viewing, it is recommend you go to your browsers File menu (not the Jupyter notebook file menu) and save the complete web page.  This will ensure the images are copied down as well.\n",
      "\n",
      "You can also execute the following cell block to create a zip-file of the files you've been working on, and download it with the link below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "rm -f openacc_files.zip\n",
      "zip -r openacc_files.zip *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**After** executing the above zip command, you should be able to download the zip file [here](files/openacc_files.zip)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}