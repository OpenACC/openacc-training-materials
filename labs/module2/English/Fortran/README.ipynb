{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling OpenACC Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab is intended for Fortran programmers. If you prefer to use C/C++, click [this link.](../C/README.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following timer counts down to a five minute warning before the lab instance shuts down.  You should get a pop up at the five minute warning reminding you to save your work!  If you are about to run out of time, please see the [Post-Lab](#Post-Lab-Summary) section for saving this lab to view offline later.\n",
    "\n",
    "Don't forget to check out additional [OpenACC Resources](https://www.openacc.org/resources) and join our [OpenACC Slack Channel](https://www.openacc.org/community#slack) to share your experience and get more help from the community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's execute the cell below to display information about the GPUs running on the server by running the `pgaccelinfo` command, which ships with the PGI compiler that we will be using. To do this, execute the cell block below by giving it focus (clicking on it with your mouse), and hitting Ctrl-Enter, or pressing the play button in the toolbar above.  If all goes well, you should see some output returned below the grey cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pgaccelinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction\n",
    "\n",
    "Our goal for this lab is to learn what exactly code profiling is, and how we can use it to help us write powerful parallel programs.  \n",
    "  \n",
    "<img src=\"../images/development-cycle.png\" width=\"70%\" height=\"70%\">\n",
    "\n",
    "This is the OpenACC 3-Step development cycle.\n",
    "\n",
    "**Analyze** your code to determine most likely places needing parallelization or optimization.\n",
    "\n",
    "**Parallelize** your code by starting with the most time consuming parts and check for correctness.\n",
    "\n",
    "**Optimize** your code to improve observed speed-up from parallelization.\n",
    "\n",
    "We are currently tackling the **analyze** step. We will use Nsight Systems profiler to get an understanding of a relatively simple sample code before moving onto the next two steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Code\n",
    "\n",
    "Our first step to analyzing this code is to run it. We need to record the results of our program before making any changes so that we can compare them to the results from the parallel code later on. It is also important to record the time that the program takes to run, as this will be our primary indicator to whether or not our parallelization is improving performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Code with PGI\n",
    "\n",
    "We are using the PGI compiler to compiler our code. You will not need to memorize the compiler commands to complete this lab, however, they will be helpful to know if you want to parallelize your own personal code with OpenACC.\n",
    "\n",
    "**pgcc**      : this is the command to compile C code  \n",
    "**pgc++**     : this is the command to compile C++ code  \n",
    "**pgfortran** : this is the command to compile Fortran code  \n",
    "**-fast**     : this compiler flag will allow the compiler to perform additional optimizations to our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pgfortran -fast -o laplace  nvtx.f90 laplace2d.f90 jacobi.f90 -L/opt/nvidia/hpc_sdk/Linux_x86_64/20.9/cuda/11.0/lib64/ -I/opt/nvidia/hpc_sdk/Linux_x86_64/20.9/cuda/11.0/include -lnvToolsExt && echo \"Compilation Successful!\" && ./laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Code Results\n",
    "\n",
    "The output from our program will make more sense as we analyze the code. The most important thing to keep in mind is that we need these output values to stay consistent. If these outputs change during any point while we parallelize our code, we know we've made a mistake. For simplicity, focus on the last output, which occurred at iteration 900. It is also helpful to record the time the program took to run. Our goal while parallelizing the code is ultimately to make it faster, so we need to know our \"base runtime\" in order to know if the code is running faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Code\n",
    "\n",
    "Now that we know how long the code took to run, and what the code's output looks like, we should be able to view the code with a decent idea of what is happening. The code is contained within two files, which you may open and view.\n",
    "\n",
    "[jacobi.f90](../Fortran/jacobi.f90)  \n",
    "[laplace2d.f90](../Fortran/laplace2d.f90)  \n",
    "  \n",
    "You may read through these two files on your own, but we will also highlight the most important parts below in the \"Code Breakdown\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Description\n",
    "\n",
    "The code simulates heat distribution across a 2-dimensional metal plate. In the beginning, the plate will be unheated, meaning that the entire plate will be room temperature. Then, a constant heat will be applied to the edge of the plate, then the code will simulate that heat distributing across the plate.  \n",
    "\n",
    "This is a visual representation of the plate before the simulation starts:  \n",
    "  \n",
    "<img src=\"../images/plate1.png\" width=\"70%\" height=\"70%\">\n",
    "  \n",
    "We can see that the plate is uniformly room temperature, except for the top edge. Within the [laplace2d.f90](../Fortran/laplace2d.f90) file, we see a subroutine called `initialize`. This function is what \"heats\" the top edge of the plate. \n",
    "  \n",
    "```fortran\n",
    "    subroutine initialize(A, Anew, m, n)\n",
    "      integer, parameter :: fp_kind=kind(1.0d0)\n",
    "      real(fp_kind),allocatable,intent(out)   :: A(:,:)\n",
    "      real(fp_kind),allocatable,intent(out)   :: Anew(:,:)\n",
    "\t  integer,intent(in)          :: m, n\n",
    "\n",
    "      allocate ( A(0:n-1,0:m-1), Anew(0:n-1,0:m-1) )\n",
    "\n",
    "      A    = 0.0_fp_kind\n",
    "      Anew = 0.0_fp_kind\n",
    "\n",
    "      A(0,:)    = 1.0_fp_kind\n",
    "      Anew(0,:) = 1.0_fp_kind\n",
    "    end subroutine initialize\n",
    "```\n",
    "\n",
    "After the top edge is heated, the code will simulate the heat distributing across the length of the plate. We will keep the top edge at a constant heat as the simulation progresses.\n",
    "\n",
    "This is the plate after several iterations of our simulation:  \n",
    "  \n",
    "<img src=\"../images/plate2.png\" width=\"70%\" height=\"70%\">\n",
    "\n",
    "That's the theory: simple heat distribution. However, we are more interested in how the code works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Breakdown\n",
    "\n",
    "The 2-dimensional plate is represented by a 2-dimensional array containing double values. These doubles represent temperature; 0.0 is room temperature, and 1.0 is our max temperature. The 2-dimensional plate has two states, one represents the current temperature, and one represents the expected temperature values at the next step in our simulation. These two states are represented by arrays **`A`** and **`Anew`** respectively. The following is a visual representation of these arrays, with the top edge \"heated\".\n",
    "\n",
    "![plate_sim2.png](../images/plate_sim2.png)  \n",
    "    \n",
    "Simulating this state in two arrays is very important for our `calcNext` function. Our calcNext is essentially our \"simulate\" function. calcNext will look at the inner elements of A (meaning everything except for the edges of the plate) and update each elements temperature based on the temperature of its neighbors.  If we attempted to calculate in-place (using only `A`), then each element would calculate its new temperature based on the updated temperature of previous elements. This data dependency not only prevents parallelizing the code, but would also result in incorrect results when run in serial. By calculating into the temporary array `Anew` we ensure that an entire step of our simulation has completed before updating the `A` array.\n",
    "\n",
    "![plate_sim3.png](../images/plate_sim3.png)  \n",
    "\n",
    "This is the `calcNext` function:\n",
    "\n",
    "```fortran\n",
    "01 function calcNext(A, Anew, m, n)\n",
    "02   integer, parameter          :: fp_kind=kind(1.0d0)\n",
    "03   real(fp_kind),intent(inout) :: A(0:n-1,0:m-1)\n",
    "04   real(fp_kind),intent(inout) :: Anew(0:n-1,0:m-1)\n",
    "05   integer,intent(in)          :: m, n\n",
    "06   integer                     :: i, j\n",
    "07   real(fp_kind)               :: error\n",
    "08\t  \n",
    "09   error=0.0_fp_kind\n",
    "10\t  \n",
    "11   do j=1,m-2\n",
    "12     do i=1,n-2\n",
    "13        Anew(i,j) = 0.25_fp_kind * ( A(i+1,j  ) + A(i-1,j  ) + &\n",
    "14                                     A(i  ,j-1) + A(i  ,j+1) )\n",
    "15        error = max( error, abs(Anew(i,j)-A(i,j)) )\n",
    "16     end do\n",
    "17   end do\n",
    "18   calcNext = error\n",
    "19 end function calcNext\n",
    "```\n",
    "\n",
    "We see on lines 13 and 14 where we are calculating the value of `Anew` at `i,j` by averaging the current values of its neighbors. Line 09 is where we calculate the current rate of change for the simulation by looking at how much the `i,j` element changed during this step and finding the maximum value for this `error`. This allows us to short-circuit our simulation if it reaches a steady state before we've completed our maximum number of iterations.\n",
    "\n",
    "Lastly, our `swap` subroutine will copy the contents of `Anew` to `A`.\n",
    "\n",
    "```fortran\n",
    "01 subroutine swap(A, Anew, m, n)\n",
    "02   integer, parameter        :: fp_kind=kind(1.0d0)\n",
    "03   real(fp_kind),intent(out) :: A(0:n-1,0:m-1)\n",
    "04   real(fp_kind),intent(in)  :: Anew(0:n-1,0:m-1)\n",
    "05   integer,intent(in)        :: m, n\n",
    "06   integer                   :: i, j\n",
    "07 \n",
    "08   do j=1,m-2\n",
    "09     do i=1,n-2\n",
    "10       A(i,j) = Anew(i,j)\n",
    "11     end do\n",
    "12   end do\n",
    "13 end subroutine swap\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Profile the Code\n",
    "\n",
    "By now you should have a good idea of what the code is doing. If not, go spend a little more time in the previous sections to ensure you understand the code before moving forward. Now it's time to profile the code to get a better understanding of where the application is spending its runtime. To profile our code we will be using Nsight Systems.\n",
    "\n",
    "\n",
    "Nsight Systems tool offers system-wide performance analysis in order to visualize application’s algorithms, help identify optimization opportunities, and improve the performance of applications running on a system consisting of multiple CPUs and GPUs. \n",
    "\n",
    "#### Nsight Systems Timeline\n",
    "- CPU rows help locating CPU core's idle times. Each row shows how the process' threads utilize the CPU cores.\n",
    "<img src=\"../images/cpu.png\" width=\"80%\" height=\"80%\">\n",
    "\n",
    "- Thread rows shows a detailed view of each thread's activity including OS runtime libraries usage, CUDA API calls, NVTX time ranges and events (if integrated in the application).\n",
    "<img src=\"../images/thread.png\" width=\"80%\" height=\"80%\">\n",
    "\n",
    "- CUDA Workloads rows display Kernel and memory transfer activites. \n",
    "<img src=\"../images/cuda.png\" width=\"80%\" height=\"80%\">\n",
    "\n",
    "### Profiling using command line interface \n",
    "To profile your application, you can either use the Graphical User Interface(GUI) or Command Line Interface (CLI). During this lab, we will profile the mini application using CLI.\n",
    "\n",
    "The Nsight Systems command line interface is named `nsys`. Below is a typical command line invocation:\n",
    "\n",
    "`nsys profile -t nvtx --stats=true --force-overwrite true -o laplace ./laplace`\n",
    "\n",
    "where command switch options used for this lab are:\n",
    "- `profile` – start a profiling session\n",
    "- `-t`: Selects the APIs to be traced (nvtx and openacc in this example)\n",
    "- `--stats`: if true, it generates summary of statistics after the collection\n",
    "- `--force-overwrite`e: if true, it overwrites the existing generated report\n",
    "- `-o` – name for the intermediate result file, created at the end of the collection (.qdrep filename)\n",
    "\n",
    "**Note**: You do not need to memorize the profiler options. You can always run `nsys --help` or `nsys [specific command] --help` from the command line and use the necessary options or profiler arguments.\n",
    "For more info on Nsight profiler and NVTX, please see the __[Profiler documentation](https://docs.nvidia.com/nsight-systems/)__.\n",
    "\n",
    "###<a name=\"viewreport\"></a>How to view the report\n",
    "When using CLI to profile the application, there are two ways to view the profiler's report. \n",
    "\n",
    "1) On the Terminal using `--stats` option: By using `--stats` switch option, profiling results are displayed on the console terminal after the profiling data is collected.\n",
    "\n",
    "<img src=\"../images/laplas3.png\" width=\"100%\" height=\"100%\">\n",
    "\n",
    "2) NVIDIA Nsight System GUI: After the profiling session ends, a `*.qdrep` file will be created. This file can be loaded into Nsight Systems GUI using *File -> Open*. If you would like to view this on your local machine, this requires that the local system has CUDA toolkit installed of same version and the Nsight System GUI version should match the CLI version. \n",
    "\n",
    "**NOTE**: To be able to see the Nsight System profiler output, please download Nsight System latest version from [here](https://developer.nvidia.com/nsight-systems).\n",
    "\n",
    "To view the profiler report, simply open the file from the GUI (File > Open).\n",
    "\n",
    "<img src=\"../images/nsight_open.png\" width=\"80%\" height=\"80%\">\n",
    "\n",
    "### Using NVIDIA Tools Extension (NVTX) \n",
    "NVIDIA Tools Extension (NVTX) is a C-based Application Programming Interface (API) for annotating events, time ranges and resources in applications. NVTX brings the profiled application’s logic into the Profiler, making the Profiler’s displayed data easier to analyse and enables correlating the displayed data to profiled application’s actions. \n",
    "\n",
    "During this lab, we profile the application using Nsight Systems command line interface and collect the timeline. We will also be tracing NVTX APIs (already integrated into the application). \n",
    "\n",
    "The NVTX tool is a powerful mechanism that allows users to manually instrument their application. NVIDIA Nsight Systems can then collect the information and present it on the timeline. It is particularly useful for tracing of CPU events and time ranges and greatly improves the timeline's readability. \n",
    "\n",
    "**How to use NVTX**: For Fortran codes, use the Fortran module to instrument. Add `use nvtx` in your source code and wrap parts of your code which you want to capture events with calls to the NVTX API functions. For example, try adding `call nvtxStartRange(\"main\")` in the beginning of your `main()` function, and `call nvtxEndRange()` just before the return statement in the end.\n",
    "\n",
    "The sample code snippet below shows the use of range events.The resulting NVTX markers can be viewed in Nsight Systems timeline view. \n",
    "\n",
    "```fortran\n",
    "  call nvtxStartRange(\"while\")\n",
    "  do while ( error .gt. tol .and. iter .lt. iter_max )\n",
    "\n",
    "    call nvtxStartRange(\"calc\")\n",
    "    error = calcNext(A, Anew, m, n)\n",
    "    call nvtxEndRange\n",
    "\n",
    "    call nvtxStartRange(\"swap\")\n",
    "    call swap(A, Anew, m, n)\n",
    "    call nvtxEndRange\n",
    "\n",
    "    if(mod(iter,100).eq.0 ) write(*,'(i5,f10.6)'), iter, error\n",
    "\t\n",
    "    iter = iter + 1\n",
    "\n",
    "  end do\n",
    "  call nvtxEndRange \n",
    "  \n",
    "```\n",
    "\n",
    "<img src=\"../images/nvtx.PNG\" width=\"80%\" height=\"80%\">\n",
    "\n",
    "Detailed NVTX documentation can be found under the __[CUDA Profiler user guide](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#nvtx)__.\n",
    "\n",
    "We will start by profiling the laplace executable that we created earlier using the command line option first. Run the `nsys` command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nsys profile -t nvtx --stats=true --force-overwrite true -o laplace ./laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's checkout the profiler's report. [Download the profiler output](laplace.qdrep) and open it via the GUI. To view the profiler report locally, please see the section on [How to view the report](#viewreport).\n",
    "\n",
    "<img src=\"../images/nsys2.png\" width=\"100%\" height=\"100%\">\n",
    "\n",
    "If we zoom in, we can see the time that each individual portion of our code took to run. These portions have been marked with NVTX and can be seen on the NVTX row on the timeline view. This information is important because it allows us to make educated decisions about which parts of our code to optimize first. To get the bang for our buck, we want to focus on the most time-consuming parts of the code. \n",
    "\n",
    "Next, we will compile, run, and profile a parallel version of the code, and analyze the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional - Where is the __c_mcopy8 coming from?\n",
    "\n",
    "When we compiled our code earlier, we omitted any sort of compiler feedback. It turns out that even with a sequential code, the compiler is performing a lot of optimizations. If you compile the code again with the `-Minfo=opt` flag, which instructs  the compiler to print additional information how it optimized the code, then it will become more obvious where this strange routine came from. Afterwards, you should see that the `__c_mcopy8` is actually an optimzation that is being applied to the **`swap`** function. Notice in the output below that at line 64 of `laplace2d.c`, which happens inside the `swap` routine, that the compiler determined that our loops are performing a memory copy, which it believes can be performed more efficiently by calling the `__c_mcopy8` function instead.\n",
    "\n",
    "```\n",
    "laplace2d.f90:\n",
    "swap:\n",
    "     65, Memory copy idiom, loop replaced by call to __c_mcopy8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pgfortran -fast -Minfo=opt -o laplace nvtx.f90 laplace2d.f90 jacobi.f90 -L/opt/nvidia/hpc_sdk/Linux_x86_64/20.9/cuda/11.0/lib64/ -I/opt/nvidia/hpc_sdk/Linux_x86_64/20.9/cuda/11.0/include -lnvToolsExt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Our Parallel Code on Multicore CPU\n",
    "\n",
    "In a future lab you will run parallelize the code to run on a multicore CPU. This is the simplest starting point, since it doesn't require us to think about copying our data between different memories. So that you can experience profiling with Nsight Systems on a multicore CPU, a parallel version of the code has been provided. You will be able to parallelize the code yourself in the next lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pgfortran -fast -ta=multicore -Minfo=accel -o laplace_parallel ./solutions/parallel/nvtx.f90 ./solutions/parallel/laplace2d.f90 ./solutions/parallel/jacobi.f90 -L/opt/nvidia/hpc_sdk/Linux_x86_64/20.9/cuda/11.0/lib64/ -I/opt/nvidia/hpc_sdk/Linux_x86_64/20.9/cuda/11.0/include -lnvToolsExt && ./laplace_parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Multicore Code using PGI\n",
    "\n",
    "Again, you do not need to memorize the compiler commands to complete this lab. Though, if you want to use OpenACC with your own personal code, you will want to learn them.\n",
    "\n",
    "**-ta** : This flag will tell the compiler to compile our code for a specific parallel hardware. TA stands for **\"Target Accelerator\"**, an accelerator being any device that accelerates performance (in our case, this means parallel hardware.) Omitting the -ta flag will cause the code to compile sequentially.  \n",
    "**-ta=multicore** will tell the compiler to parallelize the code specifically for a multicore CPU.  \n",
    "**-Minfo** : This flag will tell the compiler to give us some feedback when compiling the code.  \n",
    "**-Minfo=accel** : will only give us feedback about the parallelization of our code.  \n",
    "**-Minfo=opt** : will give us feedback about sequential optimizations.  \n",
    "**-Minfo=all** : will give all feedback; this includes feedback about parallelizaton, sequential optimizations, and even parts of the code that couldn't be optimized for one reason or another.  \n",
    "\n",
    "If you would like to see the c_mcopy8 from earlier, try switching the Minfo flag with `-Minfo=accel,opt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Profiling Multicore Code\n",
    "\n",
    "Now, let's profile the application and checkout the NVTX row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nsys profile -t nvtx --stats=true --force-overwrite true -o laplace_parallel ./laplace_parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's checkout the profiler's report. [Download the profiler output](laplace_parallel.qdrep) and open it via the GUI and checkout the NVTX row on the timeline view. To view the profiler report locally, please see the section on [How to view the report](#viewreport).\n",
    "\n",
    "<img src=\"../images/nsys_parallel2.png\" width=\"100%\" height=\"100%\">\n",
    "\n",
    "As you can see, the application runtime decreases due to the fact that we can now execute portions of our code in parallel by spreading the work across multiple threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Now we have a good understanding of how our program is running, and which parts of the program are time consuming. In the next lab, we will parallelize our program using OpenACC.\n",
    "\n",
    "We are working on a very simple code that is specifically used for teaching purposes. Meaning that, in terms of complexity, it can be fairly underwhelming. Profiling code will become exponentially more useful if you chose to work on a \"real-world\" code; a code with possibly hundreds of functions, or millions of lines of code. Profiling may seem trivial when we only have 4 functions, and our entire code is contained in only two files, however, profiling will be one of your greatest assets when parallelizing real-world code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Task\n",
    "\n",
    "For right now, we are focusing on multicore CPUs. Eventually, we will transition to GPUs. If you are familiar with GPUs, and would like to play with a GPU profile, then feel free to try this bonus task. If you do not want to complete this task now, you will have an opportunity in later labs (where we will also explain more about what is happening.)\n",
    "\n",
    "Run this script to compile/run our code on a GPU and then profile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pgfortran -fast -ta=tesla -Minfo=accel -o laplace_gpu ./solutions/gpu/nvtx.f90 ./solutions/gpu/laplace2d.f90 ./solutions/gpu/jacobi.f90 -L/opt/nvidia/hpc_sdk/Linux_x86_64/20.9/cuda/11.0/lib64/ -I/opt/nvidia/hpc_sdk/Linux_x86_64/20.9/cuda/11.0/include -lnvToolsExt && ./laplace_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nsys profile -t nvtx,openacc --stats=true --force-overwrite true -o laplace_gpu ./laplace_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's checkout the profiler's report. [Download the profiler output](laplace_gpu.qdrep) and open it via the GUI and compare with the previous reports. To view the profiler report locally, please see the section on [How to view the report](#viewreport).\n",
    "\n",
    "\n",
    "<img src=\"../images/nsys_gpu.png\" width=\"100%\" height=\"100%\">\n",
    "\n",
    "Expand the GPU row on the timeline view to checkout the kernels and memory movements.\n",
    "\n",
    "<img src=\"../images/nsys_gpu2.png\" width=\"100%\" height=\"100%\">\n",
    "\n",
    "Happy profiling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Lab Summary\n",
    "\n",
    "If you would like to download this lab for later viewing, it is recommend you go to your browsers File menu (not the Jupyter notebook file menu) and save the complete web page.  This will ensure the images are copied down as well.\n",
    "\n",
    "You can also execute the following cell block to create a zip-file of the files you've been working on, and download it with the link below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -f openacc_files.zip\n",
    "zip -r openacc_files.zip ../C/* ../Fortran/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After** executing the above zip command, you should be able to download the zip file [here](files/openacc_files.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Licensing\n",
    "This material is released by NVIDIA Corporation under the Creative Commons Attribution 4.0 International (CC BY 4.0)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
